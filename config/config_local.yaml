data:
  type: rulm # translate/paraphrase
  path: data/rulm
  source_col: text
#  target_col: dst_text
#  source_col: original
#  target_col: ru

data_train: data/processed/train
data_test: data/processed/test

model:
  type: "qwen" # mt5 or qwen
#  path: models/mt5-small/
  path: models/qwen
  device: "cuda:0"

shift:
  type: length # None/length/clusters
  path: data/processed/clusters

logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  handlers:
    console:
      level: INFO
      format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

new_model_path: models/model
model_save_path: model_checkpoints

train_size: 100_000
val_size: 10_000 

train_params:
  test_dataset_size: 100
  num_epochs: 1
  batch_size: 4
  learning_rate: 1e-3
  gamma: 0.99996
  device: 'cuda'
  kommulation_steps: 1
  eval_every_step: 10000
